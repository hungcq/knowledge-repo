# Superintelligence

## Info
- Type: book
- Author: Nick Bostrom

## Category
- Philosophy
- Technology
- History

## Structure
- Part 1: possible pathways & timing
- Part 2: what happens after intelligence explosion
- Part 3: control problem
- Part 4: bigger picture

## Goals
- Problem: control general superintelligence
- -> Only have 1 chance since unfriendly superintelligence would try not to be controlled
- Provide a better view than existing views
- Create a basis for further discussion

## Style
- Ack by author:
  - Difficult subject, many uncertainty
  - -> Missing/wrong points could invalidate the conclusions
  - Focus more on risks instead of benefits: more urgent, existential issue
- Expository, casual, highly readable, with good sense of humor
- Highly futuristic but with good reasoning
- Useful introduction at the beginning of each chapter
- Ack of differing individual capability

## Recurring themes
- Accelerated development: once a higher level of intelligence is reached
- -> Convergence

## Terms
- Seed AI: early stage AI, not yet SI
- Computronium
- Wireheading (reinforcement learning): agent modifies its reward mechanism
- Desideratum: need
- Normative vs descriptive: ideal vs reality
- GI: p.4
- Intelligence explosion: p.5
- Evolution-based method: p.10
- AI complete problem: p.17
- AI vs software: p.19
- -> Single vs general purpose distinction
- Neuromorphic: p.34
- WBE: p.35
- Recursive self-improvement: p.35
- Biological cognition: p.43
- Intelligent vs wise: p.67
- Recalcitrance: p.79 (~return to scale)
- Overhang: p.89
- Decisive strategic advantage: p.96
- Wise-singleton sustainability threshold: p.124
- Orthogonal: p.129
- Instrumental goal: p.132
- Existential risk: p.140
- Malignant failure mode: causing existential catastrophes
- Perverse instantiation: p.146
- Infrastructure profusion: p.150
- Oracles: question-answering systems that have domain-general intelligence

## Criticism
- Chap 11 goes to far into the future, read like science fiction. The basic assumptions are not solid.
- Lack of consideration regarding unexpected movement that slowdown/stop the progress: eg conflict, war
- Solving large scale problem (eg world control) is not easy, even for SI
- -> Might require lots of experiments over a long time scale
- p.171
- p.201

## Takeaway

## Main content
### Chap 1
<img src="./resources/1.drawio.svg">

### Chap 2
<img src="./resources/2.drawio.svg">

### Chap 3
<img src="./resources/3.drawio.svg">

### Chap 4
<img src="./resources/4.drawio.svg">

### Chap 5
<img src="./resources/5.drawio.svg">

### Chap 6
<img src="./resources/6.drawio.svg">

### Chap 7
<img src="./resources/7.drawio.svg">

### Chap 8
<img src="./resources/8.drawio.svg">

### Chap 9
<img src="./resources/9.drawio.svg">

### Chap 10
<img src="./resources/10.drawio.svg">