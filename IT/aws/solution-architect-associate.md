- Exam domains:
  - Security: 30%
  - Resilience: 26%
  - High performance: 24%
  - Cost optimization: 20%

# Region & availability zone
- Region:
  - Def: cluster of data centers
  - Most services are regional
  - Usually have 3 availability zones
- Considerations:
  - Compliance: data gov & legal
  - Proximity
  - Available services
  - Pricing
- Points of presence (ie edge locations) -> deliver content with low latency

# Identity & access management (IAM)
- Group: contain users, not group
- 1 user can belong to 0 -> n group
- Policy:
  - JSON doc: define permissions
  - -> Least privilege principle: give users only the needed permissions
  - Group vs inline policy: for 1 user
  - Components:
    - Version
    - ID
    - Statement:
      - Sid
      - Effect: allow/deny
      - Principal (map): user/account/role
      - Action: array allow/deny actions
      - Resource: array
      - Condition: when to apply
- Password policy:
  - Length
  - Specific character types
  - Allow users to change password
  - Password expiration
  - Password reuse prevention
- MFA = password + security device. Types of devices:
  - Virtual (eg Google Auth, Authy)
  - Universal 2nd factor (U2F) security key
  - Hardware key fob
- Access via:
  - Management console: use password + MFA
  - CLI: use access key
  - SDK (libs for code): use access key
- Access key: managed by users. Components:
  - ID: ~username
  - Secret: ~password
- Role: assign permissions to services
- Security tools (for audit):
  - Credentials report (account level): list users & status of their credentials
  - Access advisor (user level): service permissions granted & last access of those services
- Best practices:
  - Root account: shouldn't be used or shared, except for AWS account setup
  - 1 user ~ 1 person in org
  - Assign users to groups & assign permissions to groups
  - Create strong password policy
  - Use & enforce MFA
  - Use roles to give permissions to services
  - Use access key for programmatic access (CLI/SDK)
  - Audit permissions using security tools

# EC2
- Create budget to get notified about cost passing a specific budget
- EC2: elastic compute cloud
- Config:
  - Window
  - CPU: cores & compute power
  - RAM
  - Storage:
    - Network attached (EBS & EFS)
    - Hardware (EC2 instance store)
  - Network card: speed, public IP
  - Firewall rules: security group
  - Bootstrap script: config instance at first run (EC2 user data)
- Naming convention: m5.2xlarge:
  - m: instance class
  - 5: generation (higher better)
  - 2xlarge: size within the instance class
- Security group:
  - Control traffic into/out of EC2 instances (~firewall outside the instance)
  - Contain only allow rules
  - Can reference by IP/security group
  - Regulate:
    - Access to port
    - Authorized IP ranges
  - Group:Instance n:n
  - Locked down to a region/VPC combination
  - Recommendation: maintain one security group for SSH access
  - Default:
    - Block all inbound traffic
    - Allow all outbound traffic
  - Troubleshooting:
    - Timeout (not accessible): security group issue
    - Connection refused: app error (eg not launched)
- Attach role to instance to give it permissions (not aws configure)
- Purchase options:
  - On-demand: short workload, predictable pricing, pay by second
  - Reserved (1/3 years):
    - Long workload (eg DB)
    - Can be sell in marketplace
    - Convertible reserved: flexible instance
  - Saving plan (1/3 years): commitment to an amount of usage, long workload.
  Usage beyond saving plan billed at on-demand price.
  - Spot instance:
    - Short workload, resistant to failure, cheapest, can lose instance if someone paying more
    - -> Define max spot price & get the instance when current spot price < max
    - Create via spot request
    - Spot request is independent of spot instance
    - -> To terminate: cancel request then terminate instance
    - Spot fleet: set of spot instances + (optional) on-demand instances:
      - Try to meet capacity within price constraints
      - Define launch pools: instance type, OS, AZ
      - Strategies:
        - Lowest price pool
        - Diversified: distributed across pools
        - Capacity optimized: highest capacity pool
        - Price capacity optimized (recommended): highest capacity -> lowest price
  - Dedicated host:
    - Book entire physical server, control instance placement
    - To address compliance requirement/software licence per socket/core/VM
    - Purchase options:
      - On-demand
      - Reserved
    - Most expensive
  - Dedicated instance: no other customers share the hardware
  - Capacity reservation: reserve on-demand capacity in a specific AZ for any duration
  - -> Suitable for short-term uninterrupted workload on specific AZ
- Private IP: access the internet via NAT + internet gateway
- Elastic IP:
  - IPv4
  - Used to have fixed IP for EC2 instance
  - Can be attached to one instance at a time
  - -> If one instance fails, can move to another instance
  - Max: 5 per account
  - Best practice: use random public IP & assign DNS name to instance or use LB
- Placement group: control over EC2 instances placement strat:
  - Cluster: into low latency cluster (same rack) within AZ -> higher risk of failure
  - Spread: spread over underlying hardware (max 7 instances per group per AZ) -> for critical apps
  - Partition: spread over partitions (on dif racks, max 7 per AZ). Partitions are separated from each other's failure.
  - -> Used for partition-aware app (eg Kafka, Hadoop)
- -> Select when launch EC2 instance
- Elastic network interface (ENI):
  - Logical component in VPC representing a virtual network card
  - Attributes:
    - 1 primary private v4 IP
    - 1+ secondary private v4 IP
    - 1 public IPv4
    - 1+ security group
    - 1 MAC address
  - Can be created independently & move (attach) to EC2 on the fly for failover
  - Bound to specific AZ
- -> Use to have more control over private IP
- Hibernate: preserve RAM state into disk
- -> Faster boot
## Storage
- EBS (elastic block storage):
  - Network device that can be attached to instances while running
  - -> Store data even after terminated
  - Can be mounted to 1 instance at a time
  - Bound to AZ -> need to snapshot to move between AZ
  - Billed for provision capacity
  - Delete on termination attribute
  - Volume types:
    - gp2/3: general purpose SSD. gp3 can set IOPS independently (not depend on size)
    - io1/2: high performance SSD, provision IOPS. Support EBS multi-attach:
      - To multiple EC2 instances (max 16) in the same AZ
      - File system must be cluster-aware
      - Apps must handle concurrent write
    - -> When need >16k IOPS, suitable for DBs. Max IOPS io1: 64k, max IOPS io2 block express: 256k.
    - -> Higher IOPS must use instance store.
    - st l: low cost, general purpose HDD
    - sc l: lowest cost, low throughput HDD
  - -> HDD can't be boot volume
- EBS snapshot:
  - Can be copied between AZ/region
  - Can be archived: cheaper, need time to restore
  - Delete: moved to recycle bin
  - Fast snapshot restore: force full initialization of snapshot to have no latency on first use
- AMI (amazon machine image):
  - Customization of EC2 instance (eg software, config)
  - -> Faster boot & config time
  - Built for specific region, can be copied across regions
  - Can launch instances from:
    - Public AMI
    - Your own AMI: need to create & maintain
    - Marketplace AMI: created & sold by others
- Instance store:
  - Higher performance hardware disk attached to EC2 instance (local)
  - Ephemeral, risk of failure -> use for buffer, cache, temp content
  - -> Need backup & replication
- EBS encryption:
  - Layer: data, data transfer, snapshot
  - Chars: automatically handled, minimal impact on latency, use KMS keys (AES-256)
  - Encrypt an unencrypted volume: create unencrypted snapshot -> copy as encrypted -> create volume from snapshot
- EFS (elastic file system):
  - Def: managed network file system that can be mounted on any EC2
  - Chars:
    - Can be bound to EC2 instances cross AZs
    - Highly available, automatically scalable, expensive
    - Work with Linux based OS (POSIX file system)
    - Encryption at rest using KMS
  - Use cases: content management, web serving...
  - Performance classes:
    - Scale
    - Performance mode (set at creation):
      - General purpose: latency sensitive use case
      - Max IO: higher latency, throughput & parallelism
    - Throughput mode:
      - Bursting
      - Provisioned: set throughput regardless of storage size
      - Elastic: scale based on workload
  - Storage classes:
    - Storage tiers:
      - Standard: for frequently accessed file
      - Infrequent access (EFS-IA): can be managed via life cycle policy
    - Availability & durability:
      - Standard: good for production
      - One zone: good for dev, back up enabled by default, one zone IA

# Availability & scalability: ELB & ASG
- ELB:
  - Managed & maintained by AWS, few config provided
  - Highly integrated with other AWS services
  - Health check at target group level
  - Can be setup as internal (private) or external (public)
  - Use security group
  - Types:
    - Classic (old generation) - not tested: HTTP, HTTPS, TCP, SSL
    - Application: HTTP, HTTPS, web socket:
      - Support LB across target groups:
        - EC2 instances: autoscaling group
        - ECS tasks: HTTP apps/containers within same machine, managed by ECS
        - Lambda functions: translate HTTP request into JSON event
        - Private IP addresses
      - Routing based on:
        - Hostname
        - Path
        - Query
        - Header
      - Has port mapping feature to work with dynamic port
    - Network (layer 4): TCP, TLS, UDP:
      - Higher load, lower latency
      - Has 1 static IP per AZ -> easy to whitelist, support elastic IP
      - Target groups:
        - EC2 instances
        - Private IP addresses
        - Application load balancer
      - Health check supports TCP, HTTP, HTTPS
    - Gateway (layer 3 - network layer - IP protocol):
      - Act as gateway (eg firewall, traffic inspection purpose)
      - Use case: deploy, manage, scale a fleet of virtual appliances on AWS
      - Traffic path: users -> gateway LB -> target group of virtual appliances (analyze traffic) -> gateway LB -> apps
      - Functions:
        - Transparent network gateway
        - Load balancing
      - Use GENEVE protocol on port 6081
      - Target groups:
        - EC2 instances
        - Private IPs
- Sticky sessions (session affinity):
  - Def: same client to the same instance
  - Work for: classic, app & network LB
  - Mechanism: cookies with custom expiration
  - Cookies types:
    - Application-based:
      - Custom: generated by target, must be specified individually for each target group
      - App: generated by load balancer. Name: AWSALBAPP.
    - Duration-based: generated by LB. Name: AWSALB, AWSCLB
- Cross-zone LB:
  - Distribute traffic evenly across all instances in all AZs
  - -> Without it: distribute evenly across AZs
  - App/classic: enabled/disabled by default, not charged for inter AZ traffic
  - Network/gateway LB: disabled by default, charged for inter AZ traffic
- SSL:
  - Clients can use SNI (server name indication) to specify host name they reach -> server select the correct cert
  - -> Allow loading multiple SSL certs into 1 server -> support multiple listeners with multiple SSL certs
  - -> Only work for ALB, NLB, cloud front
- Connection draining (de-registration delay):
  - Def: time to complete in-flight request when the instance is de-registering or unhealthy
  - -> Stop sending new requests to the unhealthy instance
  - Set to low value if requests are short
- ASG (autoscaling group):
  - Add/remove instance to match increasing/decreasing load
  - Can have min/desired/max instances
  - Auto register new instances to the LB
  - Auto terminate instances marked as unhealthy by LB
  - Auto create new instance when one is terminated (eg unhealthy)
  - Attributes:
    - Launch template (~when create new EC2 instances)
    - Min, max & initial capacity
    - Scaling policies:
      - Dynamic:
        - Target tracking (eg 40% average CPU)
        - Simple/step scaling (eg when an alarm is trigger, add/remove x instances)
        - Scheduled action (eg increase min capacity to x at 10pm Fridays)
      - Predictive: analyze historical load -> generate forecast -> schedule scaling actions
  - Scaling metrics:
    - Average CPU
    - Request count per target
    - Average network in/out: if app is network bound
    - Custom metric
  - Scaling cooldown: period of not launching/terminating new instances after a scaling action
  - -> Allow metrics to stabilize
  - Can be triggered via Cloud watch alarm (eg for average CPU metric)
  - Should use ready to use AMI for faster setup

# Data
## RDS (relational database service)
- Managed SQL DB (maintained infra, backup, read replica, vertical & horizontal scalability, availability, monitoring)
- -> Can't SSH into underlying EC2 instances
- Offered DB: Postgres, MySQL, MariaDB, Oracle, Microsoft SQL Server, Aurora
- Storage autoscaling:
  - Need to set maximum storage threshold
  - Auto modify storage when:
    - Free storage < 10%
    - Low storage lasted > 5 min
    - 6 hours passed since last modification
- Read replica:
  - Same AZ, cross AZs or cross regions
  - Eventual consistency
  - Need to add replica address to apps
  - Network cost of data replication: only for cross regions
- RDS multi AZs (disaster recovery):
  - Sync replication to standby replica: use one DNS -> automatic failover -> increase availability
  - Can set up read replica as standby replica
  - 0 downtime operation: just need to modify RDS DB attribute
- RDS custom:
  - Def: managed Oracle/Microsoft SQL Server DB with OS & DB customization
  - Can access underlying DB & OS to config, patch, enable native features, access underlying EC2 instances using SSH
  - Need to deactivate automation mode to perform customization, should take snapshot before, for recovery
- Aurora:
  - MySQL/Postgres compatible
  - Cloud optimized: 5x/3x performance over MySQL/Postgres on RDS
  - Up to 15 read replicas, auto-scaled, fast replication compared to MySQL. Also serve as standby for failover.
  - Instantaneous failover
  - Cost ~20% more than RDS
  - High availability & scalability: 6 copies of data across 3 AZs. Self-healing with peer to peer replication.
  - Support cross region replication
  - Clustering:
    - Write endpoint: auto point to the master, even when failover
    - Read endpoint: load balancing to the read replicas
  - Backtrack: restore data at any point in time without backups
  - Advanced features:
    - Custom endpoint: define subset of replica instances as a custom endpoint
    - -> Allow query subset of read replicas (eg to run analytical query)
    - Serverless:
      - Def: automated DB instantiation & autoscaling based on actual usage
      - Use case: infrequent, unpredictable workload
      - Pay per second, can be more cost-effective
      - Mechanism: client connect to proxy fleet (managed Aurora autoscaling instances)
    - Multi-master: allow continuous write availability. Every replica is a writer node.
    - Global Aurora: 2 types:
      - Cross region read replicas
      - Global DB: 1 primary region, up to 5 secondary (read only) regions, less than 1 sec for cross region replication
    - Machine learning:
      - Def: allow adding ML based predictions to app via SQL
      - Mechanism: SQL query -> Aurora connect to ML services -> return result
      - Optimized & secured integration with AWS ML (SakeMaker - any ML model, Comprehend - sentiment analysis)
- Backup:
  - Automated:
    - Daily full backup
    - Transaction log backup every 5 mins
    - 1-35 day of retention. Disabled by setting to 0 day (can't for Aurora).
  - Manual snapshot: can store for any time period
  - -> Can snapshot & restore to save cost, compared to stopped DB (still cost money)
  - Restoration:
    - Create new DB
    - For MySQL RDS/Aurora, can restore from S3 backup into new DB instance
  - Cloning:
    - Created from existing cluster
    - Faster than snapshot & restore: use copy on write mechanism
    - Use case: create staging DB from production DB
- Security:
  - At rest encryption: set at launch time
  - -> To encrypt unencrypted DB, need to: create snapshot -> copy snapshot as encrypted -> restore from snapshot
  - In flight encryption: use AWS TLS cert on client side
  - IAM auth: use IAM roles to connect to DB instead of username & password
  - Security group: control network access
  - Audit logs: can be enabled & sent to Cloud Watch for longer retention
- RDS proxy:
  - Def: managed DB proxy for RDS
  - Mechanism: client -> proxy -> RDS instances
  - No code change required
  - Advs:
    - Pool connections to DB
    - -> Reduce load & open connections to actual RDS instances
    - Reduce failover time by 66%
    - Enforce IAM auth to connect to DB. Credentials stored in Secrets Manager.
  - Not publicly accessible
  - Use case: lambda functions
## Elastic cache
- Def: managed Redis/Memcached: maintenance, patching, optimization, setup, configuration, monitoring, backup & recovery
- Require code change
- Use cases:
  - DB cache: need to handle cache hit, cache miss (read DB & write to cache) in code
  - Store user session
- Features:
  - Redis:
    - Multi AZ with auto failover
    - Read replicas for scalability & availability
    - Durability using AOS persistence
    - Backup & restore
    - Support set & sorted set
  - Memcached:
    - Multi nodes for sharding
    - No replication -> no high availability
    - Non persistent
    - No backup & restore
    - Multi-thread architecture
- Security:
  - Support IAM auth: use for AWS API level security
  - Redis auth:
    - Set password/token when creating Redis cluster
    - Extra level of security on top of security group
    - Support SSL inflight encryption
  - Memcached: support SASL based auth
- Patterns:
  - Lazy loading: all read data is cached, cache data can be stale
  - Write through: update cache when write
  - Session store
- Use case: Redis sorted set for gaming leaderboards
- Important ports (FTP 21, SSH SFTP 22, HTTP 80 HTTPS 443) vs DB ports (>1k)

# Route 53
## DNS
- Hostname -> IP address
- Hierarchical structure (right to left)
- Domain registrar (vs DNS service provider). Usually also provide DNS service.
- DNS record
- Zone file: contain DNS records
- Name server: resolve DNS queries
- Top level domain (eg com, org), second level domain. Local DNS server get addresses from each domain level DNS server.
- -> Cache IP in local web browser & local DNS server
## Route 53
- Functions:
  - Highly available, scalable, fully managed authoritative DNS (customer can update DNS records)
  - Domain registrar
- Features:
  - Resource health check
  - 100% availability SLA
- Record: how to route traffic for a domain. Attributes:
  - Domain, subdomain name
  - Record types:
    - A: hostname -> IPv4
    - AAAA: hostname -> IPv6
    - CNAME: hostname -> A/AAAA hostname. Can't create for top node of DNS space (eg example.com. www.example.com can)
    - NS: IPs of name servers for hosted zone -> control how traffic is routed for a domain
    - Others
  - Value: IP
  - Routing policy
  - TTL: cache time at DNS resolvers
- Hosted zone:
  - Def: container for records defining how to route traffic to a domain & its subdomains
  - Types:
    - Public: Internet record
    - Private: how to route traffic within/cross VPCs (private domain name)
- Alias:
  - Point hostname to AWS resource
  - Work for root domain (vs CNAME record)
  - Free
  - Native health check
  - Always of type A/AAAA for AWS resources
  - Auto recognize change in IP
  - Targets: eg ALB, Cloud Front distributions, API gateway, Beanstalk, S3. Not work for EC2 DNS name.
- Routing policy: how to respond to DNS queries. Types:
  - Simple: one AWS resource (alias)/IP/multi IPs (client chooses a random one), no health check
  - Weighted: control % of request go to each specific resource, have health check
  - -> Allow LB, traffic routing (eg failover, new version testing)
  - Failover: based on health check. Define primary & secondary records.
  - Latency based: based on traffic between users & AWS regions
  - Geolocation:
    - Based on user location
    - Use cases: web localization, content restriction, LB
    - Should have default record when there is no matching location
    - Can associate with health check
  - Multi-value answer:
    - Route to multiple resources
    - Associate with health check -> only return healthy resources (vs simple routing - might include unhealthy resources)
  - -> Not a substitute for ALB
  - Geo proximity (using Route 53 traffic flow feature):
    - Bias def: ability to move traffic to resources. Positive/negative: increase/decrease size of the geographic region.
    - Resource types:
      - AWS resource
      - Non AWS resource (latitude & longitude)
    - Usage: shift more traffic to a specific region
  - IP based:
    - Based on client IP
    - Define list of CIDRs for client (eg 1.2.3.0 cover all 1.2.3.x). Mapping IP to endpoint.
    - Use case: route users from an ISP to specific endpoint
- Health check:
  - HTTP health check only works for public resources
  - Automated DNS failover. Monitor:
    - Endpoint (eg AWS resource):
      - ~15 global health checkers in dif regions will check the endpoint health
      - Healthy if >18% health checkers report healthy
      - Status code: 2xx/3xx
      - Can customize to check first 5120 bytes of response
      - Need to config router/firewall to allow health checkers
    - Other health checks (calculated health check):
      - Combine using AND/OR/NOT
      - Max 256 child health checkers
      - Can specify num of child health checks to pass
    - Cloud Watch alarms:
      - Useful for private resource because route 53 health checkers are outside VPC
      - Create CW metric & CW alarm -> associate health check with the alarm
  - Integrated with Cloud Watch metric
- Use as DNS service provider:
  - Create hosted zone in Route 53
  - Update NS record on 3rd party domain registrar to use Route 53 name servers

# Solution architecture discussion
- 5 pillars:
  - Cost
  - Performance
  - Reliability
  - Security
  - Operational excellence
- WhatIsTheTime: stateless web app:
  - 1 instance, scaling vertically
  - -> Elastic IP
  - Scaling horizontally
  - -> DNS, A record, multiple IPs
  - -> DNS, Alias record + ELB + health check for availability
  - Autoscaling group: reduce manual operation effort
  - -> Multi AZs for availability
  - Reserved instance for cost saving
- MyClothes: stateful web app: online shopping with cart:
  - ELB stateful session: maintain user session
  - -> Cookies: heavy request, need validation
  - -> Server session in ElastiCache/DynamoDB, session ID stored in cookies
  - RDS stores user data
  - -> Cache/read replicas to scale read
  - Multi Azs for ELB, ASG, RDS, ElastiCache for availability
  - Security group ref each other to restrict to private traffic (except LB) for security
- MyWordPress: global scale, support picture upload & access:
  - File storage: EBS volume attach to 1 EC2 instance
  - -> EFS for scalability, use ENI attached to EC2 instances to connect to EFS
  - Aurora RDS for easy multi AZs & read replicas
- Instantiate apps quickly:
  - EC2: use Golden AMI: install OS, app dependencies beforehand
  - -> Beanstalk to mix Golden AMI & dynamic user data script
  - RDS DB: restore from snapshot -> schema ready
  - EBS volume: restore from snapshot: disk formatted & have data
- Elastic Beanstalk:
  - Def: dev centric view of deploying an app on AWS
  - -> Managed service, dev do configuration & code
  - Use commonly used components: eg EC2, ASG, ELB, RDS
  - Cost:
    - Beanstalk: free
    - Other components: cost money
  - Components:
    - App: collections of Beanstalk components (envs, versions, configs)
    - App version: iteration of app code
    - Env:
      - Def: collection of AWS resources running an app version
      - Tiers: web env tier & worker env tier (process work using queue, scale based on queue load)
      - Can create multiple env
    - Process: create app -> upload app version -> launch env -> manage env
    - Deployment mode:
      - Single instance: suitable for dev
      - High availability with LB & RDS failover: suitable for production

# S3
- 